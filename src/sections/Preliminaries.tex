\chapter{Preliminaries}

Motion planning is the task of manipulating a robot's configurations so that,
given an initial and goal state or posture, the planner (black box), is able to
create a sequence of actions that gives a feasible or optimal path through the
overarching planning environment, usually referred to as the world space. Thus a
motion planner can be seen as a machine which given an input: a world, and
initial and goal states, produces a sequence of actions to move the robot from
its initial to the desired goal configuration. This plan is then passed on to
the trajectory generator in the system. Generally, planners can be separated
into complete and non-complete planners, meaning that given enough time, all
motion planning problems are solvable, only the solution is NP-Hard. Thus
feasible solutions will have to make a compromise. A lot of planners in use
today are probabilistically complete, meaning that they converge to a optimal
solution given infinite time. There is a difference between on-line and off-line
motion planning, whereas the offline algorithm plans in a static environment,
the online algorithm is run continuously. However an on-line algorithm can be
simulated by running an offline algorithm repeatedly for short intervals of
time. However, this comes with the drawback, that no guarantee can be made for
completing the task at hand \cite{Lav06}.


\section{General motion planning building blocks}

\subsection{The Robot and World Model}

In order to reason about a motion planning problem, a certain reference
framework needs to be built. A mathematical model of the world, and the robot is
necessary for clearly and precisely reasoning about the problem at hand.
Therefore, in this thesis the world space (\modelworld) will be defined as
\[
  \modelworld = \R^2
\]
and obstacles are simply subsets of \modelworld. Likewise, the robot is also a
subset of the world space
\[
  \modelrobot,\, \modelobstacle \subset \modelworld
\]

Next the robot needs to be able to move around in the world space. This is done
through a rigid body transformation on the robot model
\[
  h : \modelrobot\ \rightarrow \modelworld
\]

However, the robot is more than a set of points in the world space. For example
a simple model of a car needs to know its heading as well. This information will
be referred to as the configuration space of the robot
(\modelconfigurationspace). For a simple car model this can be encoded in a
simple three dimensional vector holding the \(x\), \(y\), and \(\theta\)
parameters, like so
\[
  \modelconfigurationspace \subset SO(2),
\]
which encompass all the states the robot can be in during, and \(SE(2)\) stands
for \textit{Special Euclidean two}, and is defined as \(SE(2) = \R^2 \times
\mathsf{S}\).

\subsubsection{Configuration Space}

TODO -- fix shite!

The configuration space is a general abstraction used as a model for a wide
variety of motion planning problems. It is a manifold that arise from the
transformations applied to the robot. If the robot has n-degrees of freedom, the
set of transformations is usually a manifold of dimension n. This manifold is
called the configuration space of the robot, and is shortened
\modelconfigurationspace{}. Thus in order to solve a motion planning problem, a
search must be performed in the configuration space. Thus the motion planning
problem is now made into a question of finding the best path to traverse the
given manifold\cite{Lav06}.

Using generalized coordinates, the configuration of a robot can be modeled as a
vector with n variables for the position in the configuration space, in
literature this space is usually denoted by \modelconfigurationspace{}. As is
most common, the robot is modeled as a rigid body, in which two bodies cannot
overlap, thus points in the configuration space is separated into two sets. One
set for which the robot configuration overlaps with another object in the
configuration space, and is called \modelconfigurationspaceobst{}, and given
that the world space is represented as \modelconfigurationspace{}, the collision
free space is the given as, \(\modelconfigurationspacefree =
\modelconfigurationspace \setminus \modelconfigurationspaceobst\). The obstacle
region of the world space can be represented in a number of ways, but we will
stick to polygonal models of the obstacle space.

\subsection{Action Space}

Now that the configuration space, and how the robot model can move in the world
space is defined, the next concern is to control the movement of the robot
model, and this is where the \textit{action space} comes in. The action space is
the set of actions that can be applied at any given state the robot is in. Thus
one can model the action space as a function of the robot's state.\ e.g.
\[
  \modelactionspace(x) = \set{u \in \modelactionspace \mid \modelactionspace(x)
    \neq \emptyset }
\]

\subsection{Initial and Goal States}

A planning problem needs to have an initial condition, and a goal. It is normal
to define an initial state and a goal state as a starting and an ending point of
a planning problem. Where both the initial, and goal states can be sets of
states, meaning that it is not necessary to arrive specifically at the target
point.

\subsection{Model}

A mathematical model of the planning problem.

The \rrtfunnel\ motion planning algorithm is discrete, therefore only the
discrete motion planning formulation will be defined. Note however that there is
a rich literature surrounding the continuous case also. In fact a lot of
discrete motion planners have simply been adapted from a continous analog. Also
even though the planner itself is discrete, the configuration space can be --
and is in this thesis -- continuous.

\subsubsection{Discrete}

Let \(\mathcal{X}\) be the discrete state space, and \(\mathcal{U}(x)\) be the
set of actions available at each point \(x \in \mathcal{X}\). State transition:\
\[
  x_{k+1} = f(x_k, u_k)
\]

\subsubsection{Path and Trajectory}

A motion plan takes the form of a path, or a trajectory. This is represented as
a function \(\phi(\alpha) \colon [0,1] \rightarrow \mathcal{X}\), where
\(\mathcal{X}\) is the configuration space of the vehicle. If the
control-execution time is considered, then the explicit model of vehicle
kinematics and/or dynamics, as well as the dynamics of the possible obstacles.
Then the trajectory is represented as a time-parameterized function of the kind
\(\pi(t) \colon [0,T] \rightarrow \mathcal{X}\), where \(T\) is the planning
horizon. Unlike the path, the trajectory describes how the configuration of the
vehicle evolves over time.

Initial and Goal States. A path is a function f \ldots

\subsection{Planning Under Uncertainty (Decision Theoretic Planning)}

All real life motion planning problems are faced with some level of uncertainty,
as errors can arise from a multiple of sources, whereas the most prevalent ones
are uncertainty in:
\begin{enumerate}
\item motion
\item sensing
\item the environment
\end{enumerate}
Thus the exact system state is never exactly known. Therefore planning under
uncertainty is done in a belief space, which is a description of the state space
using probability distributions. Planning is done in the information space, as
opposed to the state-space. Uncertainties in prediction and the current state
exist. The information space is a general structure for working with plans under
conditions of uncertainty. Thus planning can be done mostly as it is done in a
state space, albeit in a higher dimension. Thus the state transition function
can be written as
\[
  \phi_{k+1} = f_{\mathcal{I}}\left( \phi_k, \mu_k, y_{k+1} \right)
\]

\subsection{A Model of Uncertainty}

If the discrete state space model is expanded to include \(\theta\) as the space
of nature actions, and \(\ theta_k\) is the action selected by nature at step k,
then a transition is modeled as
\[
  x_{k+1} = f(x_k,u_k,\theta_k)
\]
As the actions of nature are not available beforehand, that is -- \(\theta_ k\)
is not given, thus we have
\[
  X_{k+1} = \set{ x_{k+1} \ in X \mid \exists\theta_k \in \Theta(x_k,u_k)
    \text{such that } x_{k+1} = f(x_k,u_k,\theta_k)}
\]\cite{Lav06}.

\subsection{A Plan under Uncertainty}
Since it Expected-case analysis. Worst-case analysis.

\subsection{Trajectory planning}

The \rrtfunnel\ algorithm relies on validating robust trajectories as motion
primitives for the planner. However, solving for a valid initial trajectory is a
hard control problem in itself. Thus in order to surmount this obstacle

\subsection{Reachable sets}

Of particular interest to the \rrtfunnel\ algorithm is the reachable set. A
reachable set is all the configurations that the robot can be in if started from
a particular point in the world space. Had there been no constraints on the
movement of the robot the reachable set would simply be the entire configuration
space. However, the simple car model has both \textit{kinodynamic} and
\textit{non-holonomic} constraints. This leads to the car not necessarily being
able to reach all the states in the state-space from a given starting position.
At least not given a time frame. This idea is important as it leads to the
funnel definitions that makes up the backbone of this thesis. As an example, the
reachable set for the \textit{Dubins car} will look like this

\begin{figure}
  \centering \input{figures/preliminaries/dubinsreachability.tex}
\end{figure}

\subsection{Motion primitives}

A motion primitive is a constant action applied over fixed time intervals. It is
one or more actions collected into one distinct action, usually with a goal. As
an example, the action the \textit{Dubin's car} employs is steering the angle of
the wheels. Setting the angle to a constant over a time interval can be a motion
primitive, however, it is more easily thought of as a collection of actions over
time, which embodies one bigger, more abstract action. For the car this could be
\textit{go straight}, \textit{turn left}, etc. In this way, a collection of
actions can be thought of as one simple action.

\begin{table}
  \begin{tabular}{c c c p{4cm}}
    \hline
    \hline
    Algorithm Group & Technique & Variations & Description \\
    \hline
                    &  Dijkstra's Algorithm & &Algorithm for finding the shortest weighted path in a graph.\\
                    &  \\
    Graph Search               & & D* & Capable of planning paths in unknown, partially known, and changing environments in an efficient, optimal, and complete manner..\\
                    & A* Family & Focused-D* & Informed-incremental heuristic search.\\
                    & & D*-Lite & Simpler to implement that Focused D*, slightly slower performance.\\
    \hline
                    & RRT-implementations \\
                    & & RRT\\
                    & & RRT*\\
    Sampling based Planners& & RRT*-Smart\\
                    & & RRT-SLAM\\
                    & & CC-RRT\\
                    & PRM \\
                    & & BRM & A road-map implementation that plans in belief space in order to handle uncertainties in the planning model.\\
    \hline
    Numerical Optimization &  Function Optimization \\
    \hline
  \end{tabular} 
\end{table}

\section{Funnels}

A \textit{Funnel} is a parametrization of the reachable set of a dynamical
system. This means that a \textit{Funnel} holds all the states the dynamical
system can be in during a planning task. Mathematically the reachable set of the
system is defined as
\[
  \bar{x}(0) \in \mathcal{X}_0 \implies \bar{x}(t) \in F(t), \forall t \in
  \sqb{0,T}
\]
where \(\mathcal{X}_0\) is the set of initial conditions, \(\sqb{0,T}\) the time
interval, and \(F(t)\) is the set of states that the system can be in at time
\(t\). Although this thesis concerns itself with approximating the reachable set
through \textit{Lyapunov} functions, a useful analogy is imagining the funnel
created through \textit{Monte-Carlo} simulation, where the \textit{Funnel} would
be the set of all the paths traversed by the dynamical system at hand. For a
simple car model, monte-carlo simulation of nine starting points along the
y-axis looks like~(\ref{fig:monte-carlo-sim}).

\begin{figure}
  \centering \includegraphics[scale=.5]{figures/preliminaries/montecarlofunnel}
  \caption{The simulation of N paths starting from a random point in the
    interval \(\sqb{-.5,.5}\), and controlled with a LQR controller.}
  \label{fig:monte-carlo-sim}
\end{figure}

In this thesis a \textit{Funnel} will refer to the \textit{outer approximation
  of forwards reachable sets} parameterized by a \textit{Lyapunov function}.


\subsection{Funnels}
\label{sec:Funnels}

TODO -- Create a timeline of these papers.

The term \funnel\ first appears in \cite{masonMechanicsManipulation1985}. The
\funnel{} definitions in this thesis is taken from a series of articles on
\funnel{}'s \cite{tobenkinInvariantFunnelsTrajectories2010}
\cite{tedrakeLQRtreesFeedbackMotion2009} \cite{majumdarRobustOnlineMotion2013}
\cite{majumdarFunnelLibrariesRealtime2017}
\cite{ahmadiDSOSSDSOSOptimization2017}, with the main focus being on
\cite{majumdarFunnelLibrariesRealtime2017}. Here a \funnel\ is mathematically
defined as
\[
  \bar{x}(0) \in \mathcal{X}_0 \implies \bar{x}(t) \in F(t), \forall t \in
  \sqb{0,T}
\]
where \(\mathcal{X}_0\) is the set of initial conditions, \(\sqb{0,T}\) the time
interval, and \(F(t)\) is the set of states that the system can be in at time
\(t\).

\subsection{Defining funnels}

The funnel computations will be based on the \ac{SOS} theory as developed
in~\ref{sec:Funnels}. Given a trajectory, the goal is to compute a robust
invariant set around the trajectory that will `guarantee' that the planner is
free from collisions during execution of the obtained motion plan. This robustly
invariant set is parameterized through Lyapunov function candidates, that, in
this case, will be based upon the \ac{PSD} matrix that the time-invariant
\ac{LQR} controller produces. The following presentations will be based
on~\cite{tobenkinInvariantFunnelsTrajectories2010,
  tedrakeLQRtreesFeedbackMotion2009, majumdarRobustOnlineMotion2013}, but mainly
follow the formulations, and syntax
from~\cite{majumdarFunnelLibrariesRealtime2017}.

Thus, given the nonlinear dynamical system
\begin{equation}
  \label{eq:dynamicalsystem}
  \dot{x} = f(x(t), u(t))
\end{equation}
with \(x(t)\) the state of the system at time \(t\) and \(u(t)\) the control
input. Assume that a open loop nominal trajectory \(x_0 \colon [0,T] \rightarrow
\R^n\) with control input \(u_0 \colon [0,T] \rightarrow \R^n\) is given, and
define a change of coordinates into the error coordinate frame
\[
  \bar{x}(t) = (x - x_0)(t) \\
  \bar{u}(t) = (u - u_0)(t).
\]
Then, changing~\ref{eq:dynamicalsystem} to these new coordinates one obtaines
\begin{equation}
  \dot{\bar{x}} = \dot{x} - \dot{x}_0 = f(x_0(t) + \bar{x}(t), u_0(t) + \bar{u}(t)) - \dot{x}_0(t)
\end{equation}

In order to compute a parameterized reachable set through \ac{SOS} programming
the system~\ref{eq:dynamicalsystem} needs to be polynomial, and parameterized by
\(x\) and \(t\), since the trajectory is parametrized by \(x\) and \(t\).
Therefore, through the use of a \ac{TV-LQR} controller, the control input can be
eliminated from the dynamical equation, giving
\begin{equation}
  \label{eq:dynamicclosedloop}
  \dot{\bar{x}} = f_{cl}(t,\bar{x}(t)).
\end{equation}
However, the dynamical system may still not be polynomial, which is a necessary
condition in order for this to be verified using \ac{SOS} programming. Expanding
the system~\ref{eq:dynamicclosedloop} around the nominal trajectory \(x_0\)
through a Taylor expansion of some degree high enough to capture the
nonlinearities of the system.

The goal is to parametrize a tight outer approximation of the set of states the
system may transition into during the time interval \([0,T]\). Given that
\(F(t)\) is the set of states the system (\ref{eq:dynamicclosedloop}) can be in
at time \(t\), then
\begin{equation}
  \label{eq:reachableset}
  \bar{x}(0) \in \mathcal{X}_0 \implies \x(t) \in F(t), \, \forall t \in [0,T]
\end{equation}~\cite{majumdarFunnelLibrariesRealtime2017} 
where \(\mathcal{X}_0\) is the initial condition set, and \(F(t) \subset \R^n\).

A funnel is defined in~\cite{majumdarFunnelLibrariesRealtime2017} as
\begin{definition}
  \label{def:funnel}
  A funnel associatied with a closed-loop dynamical system \(\dot{\bar{x}} =
  f_{cl}(t,x(t))\) is a map \(F \colon [0,T] \rightarrow \mathcal{P}(\R^n)\),
  from the time interval \([0,T]\) to the power set (i.e., the set of subsets)
  of \(\R^n\) so that the sets \(F(t)\) satisfy the
  condition~\ref{eq:reachableset}.
\end{definition}
Thus, \(F(t)\) is the set of reachable states that the system can be in at time
\(t\).

Next, the reachable set is paramterized through the use of Lyapunov functions,
which yields
\begin{equation}
  F(t) = \set{\bar{x}(t) \mid V(t, \bar{x}(t) \leq \rho (t))}
\end{equation}
where \(\rho (t) \colon [0,T] \rightarrow \R^+\), is a function which limits the
size of the reachable set, and \(V(t,\bar{x}(t))\) is a Lyapunov function \(V
\colon [0,T] \times \R^n \rightarrow \R^+\).

Then, by setting \(\mathcal{X}_0 \subset F(0,\bar{x})\), one can derive the
sufficient condition for containing the reachable~\ref{eq:reachableset} set in
the Lyapunov function paramterization
\begin{equation}
  \label{eq:funnelsufficient}
  V(t,\bar{x}) = \rho(t) \implies \dot{V}(t,\bar{x}) < \dot{rho}(t), \, \forall t \in [0,T]
\end{equation}
with \(\dot{V}(t,\bar{x})\) computed as
\begin{equation}
  \dot{V}(t,\bar{x}) = \frac{\partial V(t,\bar{x})}{\partial x} f_{cl}(t,\bar{x}) + \frac{\partial V(t,\bar{x})}{\partial t}
\end{equation}

Currently there are no limitations on the functions \(V\) and \(\rho\), and
hence there exists infinitely many functions with different sized reachable sets
that satisfies~\ref{eq:funnelsufficient}, and is a valid funnel in the sense of
definition~\ref{def:funnel}. In order for efficient planning to take place, the
motion primitives, meaning the size of the funnels, should be as small as
possible, and it is therefore that the size of the funnels is minimized using
the following optimization problem~\cite{majumdarFunnelLibrariesRealtime2017}

\begin{align}
  \label{eq:funneloptimizationproblem}
  &\underset{V,\rho}{\text{inf}} \; &&\int_{0}^{T} vol(F(t)) dt \\
  &\text{subject to} && V(t,\bar{x}) = \rho (t) \implies \dot{V}(t,\bar{x}) < \rho (t), \, \forall t \in [0,T] \\
  && &\mathcal{X}_0 \subset F(0,\bar{x}) \\
\end{align} 


\subsection{Computing funnels}

\subsection{Formulating the optimization problem as a SOS program}

The optimization problem in~\ref{eq:funneloptimizationproblem} would prove
impossible to solve efficiently had it not been for advances in mathematical
convex numerical optimization, as in general the problem involves searching over
an infinite function space. While the general optimization problem of searching
through the infinite function space is not amenable to efficient numerical
computation, the problem can be made computationally feasible through the use of
a \ac{SOS} programming approach.

Thus in order to make the problem amenable to a \ac{SOS} program, there are some
assumptions that need to be met by our problem formulation. Firstly the initial
condition set needs to be a \textit{semi-algebraic set}, (\ie{} parameterized by
polynomial inequalities),

\begin{equation}
  \mathcal{X}_0 = \set{\bar{x} \in \R^n \mid g_{o,i}(\bar{x}) \geq 0, \, i = 1,\ldots,N_0}
\end{equation}

Then rewriting~(\ref{eq:funneloptimizationproblem})~as in terms of positivity
and equality constraints yields
\begin{equation}
  V(t,\bar{x}) = \rho(t) \implies \dot{\rho}(t) - \dot{V}(t,\bar{x}) > 0
\end{equation}
and
\begin{equation}
  g_{0,i}(\bar{x}) \geq 0 \forall i \in \set{1,\ldots,N_0} \implies \rho(0) - V(0,\bar{x}) \geq 0
\end{equation}
which, if these functions are both polynomial, is now in the form of a \ac{SOS}
optimization problem. Then through the use of the \textit{S-procedure} one
arrives at the equations
\begin{align}
  &\dot{\rho}(t) - \dot{V}(t,\bar{x}) - L(t,\bar{x})\left[ V(t,\bar{x}) - \rho(t) \right] - L_{t}(t,\bar{x})\left[ t\left( T - t \right) \right]  && \text{is SOS}& \label{eq:sufficient-conditions}\\
  & \rho(0) - V(0,\bar{x}) - \sum_{i}^{N_{0}} L_{0,i}(\bar{x})g_{0,i}(\bar{x}) && \text{is SOS}& \\
  & L_{t}(\bar{x}), \, L_{0,i}(\bar{x}) \; &&\text{are SOS}, \, \forall i \in \set{1,\ldots,N_{0}} \label{eq:sufficient-conditions3} \\
\end{align} 
where \(L\), \(L_{t}\), and \(L_{0,i}\) are multiplier
polynomials~(\ref{sec:s-procedure})~.

The goal is to make the parametrization of the reachable set as small as
possible, and therefore minimizing the cost
function~(\ref{eq:funneloptimizationproblem})~. This is done
in~\cite{majumdarFunnelLibrariesRealtime2017}, through approximating the cost
function by first discretizing the problem and replacing the integral with a
finite sum
\begin{equation}
  \int_{0}^{T} vol(F(t)) dt \rightarrow \sum_{k=1}^{N} vol(F(t_{k})) \label{eq:discrete-costfunction}
\end{equation}
Since the Lyapunov function \(V\) in this thesis will be quadratic, \(V\) can be
written as
\begin{equation}
  V(t_{k}, \bar{x}) = {\bar{x}}^{T}S_{k}\bar{x}, \, S_{k} \succeq 0
\end{equation}
which means that the set \(F(t_{k})\) is an ellipsoid in which the volume can be
minimized through maximizing the determinant of \(S_{k}\). Which in turn can be
transformed into a \ac{SDP} problem. If an upper bound on the cost
function~(\ref{eq:discrete-costfunction}) is introduced as
\begin{equation}
  \mathcal{E} (t_{k}) = \set{\bar{x} \in \R^n \mid {\bar{x}}^{T}S_{k}\bar{x} \leq 1, \, S_{k} \succeq 0}
\end{equation}
where \( \mathcal{E} ( t_{k} ) \) is an ellipsoid containing the reachable set
\( F ( t_{k} ) \) at time \( t_{k} \). This containment constraint can be
equivalently expressed as
\begin{equation}
  V ( t_{k}, \bar{x} ) \leq \rho(t_{k})  \implies {\bar{x}}^{T}S_{k}\bar{x} \leq 1.
\end{equation}
Which when expressed using \ac{SOS} constraints is
\begin{align}
  1 - {\bar{x}}^{T}S_{k}\bar{x} - L_{\mathcal{E},k}(\bar{x})\left[ \rho(t_{k}) - V(t_{k}, \bar{x}) \right]  \qquad \text{is SOS}& \\
  L_{\mathcal{E},k}(\bar{x}) \qquad \text{is SOS.}& \\
\end{align}

Then combining the cost function~(\ref{eq:discrete-costfunction}) with the
constraints~(\ref{eq:sufficient-conditions}-\ref{eq:sufficient-conditions3}),
one arrives at

\begin{mini!}|s|[3]
  {\substack{V,\rho,L,L_{t},\\L_{0,i},S_{k},L_{\mathcal{E},k}}}{\sum_{k=1}^{N}
    \mathrm{vol}(\mathcal{E}(t_{k})) = \sum_{k=1}^{N} \mathrm{vol}(\set{ \bar{x}
      \mid {\bar{x}}^{T}S_{k}\bar{x} \leq 1 }} {\label{eq:Example1}}{}
  \addConstraint{\dot{\rho}(t) - \dot{V}(t,\bar{x}) - L(t,\bar{x}) \left[
      V(t,\bar{x}) - \rho(t) \right] - L_{t}(t,\bar{x})\left[ t\left( T - t
      \right) \right] \label{eq:optimizationconditionsos}}{&\text{is SOS}}
  \addConstraint{\rho(0) - V(0,\bar{x}) -
    \sum_{i}^{N}L_{0,i}(\bar{x})g_{0,i}(\bar{x}) }{&\text{is SOS}}
  \addConstraint{1 - {\bar{x}}^{T}S_{k}\bar{x} - L_{\mathcal{E},k}(\bar{x})
    \left[ \rho(t_{k}) - V(t_{k},\bar{x}) \right] }{&\text{is SOS}}
  \addConstraint{S_{k} \succeq 0}{}{\forall k \in \set{1,\ldots,N}}
  \addConstraint{L_{t}(t,\bar{x}),\, L_{0,i}(\bar{x})}{&\text{are SOS}}
  \addConstraint{}{}{\forall i \in \set{1,\ldots,N_{0}}\forall k \in
    \set{1,\ldots,N}}
\end{mini!}
Which is the finite dimensional optimization problem needed in order to search
for a Lyapunov function candidate.

However, this optimization problem is not convex in general, as the first
constraints are \textit{bilinear} in the decision variables, since \(L\) and
\(V\) are multiplied together. However, the problem can be solved, although not
optimally, if \(V\) and \(\rho\) are held fixed, while the other decision
variables are free, the problem is amenable to \ac{SOS} optimization. Likewise,
fixing \(L\) and \(L_{\mathcal{E},k}\), creates another \ac{SOS} optimization
program. Therefore shifting between the two sets of decision variables
\[
  \left( L,L_{t},L_{0,i},L_{\mathcal{E},k} \right)
\]
and
\[
  \left( V,\rho,L_{0,i},S_{k} \right)
\]
\cite[Majumdar]{majumdarFunnelLibrariesRealtime2017} arrives at the following
algorithm for searching for a funnel

\begin{algorithm}[H]
  \label{alg:funnelalgorithm}
  \caption{Funnel computation}
  \DontPrintSemicolon \SetAlgoNoLine

  \KwIn{\(V\) and \(\rho\)} \KwOut{Funnel}

  \(cost_{prev} = \infty\)\; converged = false \; \While{\(\neq converged\)}{
    Optimization problem 1: \;
    \begin{align*}
      \underset{\substack{L,L_{t},L_{0,i},S_{k},L_{}}}{\inf}&  \sum_{k=1}^{N} \mathrm{vol}(\mathcal{E}(t_{k}))& \\    
      \text{subject to } & V \text{ and } \rho \text{ constant.}& \\
    \end{align*}\;
    Optimization problem 2: \;
    \begin{align*}
      \underset{\substack{V,\rho, L_{t},L_{0,i},S_{k}}}{\inf}&  \sum_{k=1}^{N} \mathrm{vol}(\mathcal{E}(t_{k}))& \\    
      \text{subject to } & L \text{ and } L_{\mathcal{E},k} \text{ constant.}& \\
    \end{align*}\;
    cost = \(\sum_{k=1}^{N} \mathrm{vol}(\mathcal{E}(t_{k}))\) \;
    \If{\(\frac{cost_{prev} - cost}{cost_{prev}} < \epsilon\)} {
      converged = true
    }\;
    \(cost_{prev} = cost\)\;
  }\;
\end{algorithm}

\subsection{Approximation via time-sampling}

It is often the case that the nomial trajectory \(x_{0} \colon [0,T] \rightarrow
\R^n\) is difficult to approximate with a low degree polynomial in
time~\cite{majumdarFunnelLibrariesRealtime2017}. As this can cause funnel
computation to take a lot of time, approximating the polynomial discretely can
save a lot of time, but exactness will be
lost~\cite{majumdarFunnelLibrariesRealtime2017}. If \(t_{k} \in [0,T]\), where
\(k \in \set{1,\ldots,N}\), the optimization equations will turn into
\begin{mini}
  {\substack{V_{k}, \rho, L_{k},\\ L_{0,i}, S_{k},
      L_{\mathcal{E},k}}} % Optimization variables
  {\sum_{k=1}^{N}\mathrm{vol}(\mathcal{E}(t_{k})) = \sum_{k=1}^{N}
    \mathrm{vol}\left( \set{\bar{x} \mid {\bar{x}}^{T} S_{k} \bar{x} \leq 1}
    \right)} % Optimization function
  {\label{optidef:discrete}} % Label optimization problem
  {} % Optimization result
  % Constraints
  \addConstraint{\dot{\rho}(t_{k}) - \dot{V}_{k}(\bar{x}) - L_{k}(\bar{x})
    \left( V_{k}(\bar{x}) - \rho(t_{k}) \right)} {\qquad} {\forall k \in
    \set{1,\ldots,N}} \addConstraint{\rho(t_{1}) - V_{1}(\bar{x}) -
    \sum_{i}^{N_{0}} L_{0,i}g_{0,i}(\bar{x})} {\, \text{is SOS}} {}
  \addConstraint{1 - {\bar{x}}^{T} S_{k} \bar{x} - L_{\mathcal{E,k}} \left(
      \rho(t_{k}) - V_{k}(\bar{x}) \right)} {\, \text{is SOS}} {\forall k \in
    \set{1,\ldots,N}} \addConstraint{S_{k} \succeq 0} {} {\forall k \in
    \set{1,\ldots,N}} \addConstraint{L_{0,i}(\bar{x}), L_{\mathcal{E},k}} {\,
    \text{are SOS}} {\forall i \in \set{1,\ldots,N} \quad \forall k \in
    \set{1,\ldots,N}}
\end{mini}

\subsection{Adding uncertainty to the funnel calculation}

Following are the changes to the formulations so that a funnel takes into
account a bounded uncertainty term of the form \(\mathcal{W}) = \set{ w(t) \in
  R^d \mid g_{w,j}(w) \geq 0 \forall j = 1,\ldots,N_w}\). Adding an extra term
to the closed-loop dynamics equation
\[
  \dot{\bar{x}} = f_{cl}(t, \bar{x}(t), w(t))
\]
the requirement~(\ref{eq:reachableset}) is slightly modified so that
\begin{equation}
  \label{eq:uncertain-reachableset}
  \bar{x}(0) \in \mathcal{X} \implies \bar{x}(t) \in F(t),\, \forall t \in
  [0,T], \, \forall w \colon [0,T] \rightarrow \mathcal{W}
\end{equation} 
\(F(t)\) is the new reachable set for the uncertain system. Thus the sufficient
condition~(\ref{eq:funnelsufficient}) turns into
\begin{equation}
  \label{eq:funneluncertain-sufficient}
  V(t,\bar{x}) = \rho(t) \implies \dot{V}(t,\bar{x},w) < \dot{\rho}(t), \, \forall t \in [0,T], \, \forall w(t) \in \mathcal{W}.
\end{equation}
The Lyapunov function is calculated as
\begin{equation}
  \dot{V}(t,\bar{x}, w) = \frac{\partial V(t,\bar{x})}{\partial x} f_{cl}(t,\bar{x},w) + \frac{\partial V(t,\bar{x})}{\partial t},
\end{equation}
and the optimization condition~(\ref{eq:optimizationconditionsos}) turns into
\begin{align}
  \label{eq:optimizationconditionuncertain}
  \dot{\rho}(t) - \dot{V}(t,\bar{x},w) - L(t,\bar{x},w) \left[ V(t,\bar{x}) - \rho(t) \right] - L_{t}(t,\bar{x},w)\left[ t\left( T - t \right) \right]  & \\
  - \sum_{j=1}^{N_{w}} L_{w,j}(t,\bar{x},w)g_{w,j}(w)& \qquad \text{is SOS}  \\
  \L_{w,j}(t,\bar{x},w) \qquad \text{is SOS}, \; \forall j = 1,\ldots,N_w
\end{align}

\subsection{Only minimizing the volume of the funnel projected down into the
  xy-plane}

There is no need in minimizing the value of \(\dot{\theta}\), so in order to
minimize what we care about, i.e. the actual size of the funnel where the
physical vehicle can move, we modify our costfunction according to
\cite{majumdarFunnelLibrariesRealtime2017}. Thus, given a projection map \(\pi :
\R^n \rightarrow \R^{n_p}\). Given the ellipsoid \(\epsilon = \set{\bar{x} \in
  \R^n | \bar{x}^TS_{k}\bar{x} \leq 1}\) with
\[
  S_k^{(p)} = \p{PS_k^{-1}P^T}^{-1}
\]
Given that minimizing the volume of the ellipsoid \(\epsilon\) using an SDP
relies on maximizing the determinant of \(S_k\). Since \(det(S_k)\) is a
nonlinear function of \(S_k\), the function has to be linearized in order for it
to be handled by our solution framework (SOS-programming).
\cite{majumdarFunnelLibrariesRealtime2017} solves this by linearizing
\(det(S_k)\) at the solution of \(S_k\) from the previous iteration, and
maximizes this linearization instead. In the end this translates to
\[
  lin\p{det\p{S_k}} =
  Tr\p{P^T\p{PS_{k,0}^{-1}P^T}^{-1}PS_{k,0}^{-1}S_kS_{k,0}^{-1}}
\]
where \(S_{k,0}\) is the nominal value.

\subsection{Composition of funnels}

\subsection{Checking composability of Funnels}

In order for two \funnel's to be composable, the outlet of one \funnel\ needs to
be completely contained within the inlet of the other. This means that if
\(\mathcal{F}_1 = F_1(T)\) is the outlet of \funnel\ \(F_1\), and
\(\mathcal{F}_2 = F_2(0)\) is the inlet of \(F_2\), then
\[
  \mathcal{F}_1 \subseteq \mathcal{F}_2
\]
\label{composability}
in order for the funnels to be composable. In this thesis this composition
checking is done off-line and prior to the algorithms run. First however, how to
verify that the outlet of one \funnel\ is fully contained within the inlet of
the other.

In \cite[Majumdar and Tedrake, p.~47]{majumdarFunnelLibrariesRealtime2017}, two
funnels are sequentially composable if
\begin{definition}
  \label{def:funnel-composition}
  An ordered pair \((F1, F2)\) of funnels \(F_1 \colon [0,T_1] \rightarrow
  \mathcal{P}(\R^n)\) and \(F_2 \colon [0,T_2] \rightarrow \mathcal{P}(\R^n)\)
  is sequentially composable if \(F_1(T) \subseteq F_2(0)\).
\end{definition}

TODO - make pretty funnel picture!

Thus
\[
  V_1(T_1,\bar{x}) \leq \rho_1(T_1) \implies V_2(0,\bar{x}) \leq \rho_2(0)
\]
is an equivalent condition to \ref{composability}, and which can be checked
through the following \ac{SOS} program.
\begin{align*}
  \text{Find } \; &L(\bar{x}) \\
  \text{s.t} \; &\rho_2(0) - V_2(0,\bar{x}) - L(\bar{x})
                  \left( \rho_1(T_1) - V_1(T_1,\bar{x}) \right)
\end{align*}
\cite[Majumdar and Tedrake, p.~54]{majumdarFunnelLibrariesRealtime2017}

However in \cite[Majumdar and Tedrake]{majumdarFunnelLibrariesRealtime2017}, the
program is simply stated, and it can be helpful to take a look at the derivation
in order to further envelop ourself in the implementation of a \ac{SOS} program.

The \textit{S-procedure} enables us to limit our search to a semialgebraic set.
In this case, that set is \(\mathcal{F}_2 = \set{x \in \R^n \mid V_2(0,\bar{x})
  \leq \rho_2(0)}\), any \(x\) that is not in this set does not concern us,
which is why employing the \textit{S-procedure} is valid. In more general terms
this can be written
\[
  x \in \mathcal{F}_2 \implies p(x) \geq 0
\]
where \(p(x)\) is the \ac{SOS} polynomial that is to be verified. In this case
\(p(x)\) is \(V_2(0,\bar{x})\). Thus in order to impose the implication define
\[
  q(x) = V_2(0,\bar{x}) - \rho_2(0) - L(\bar{x}) \left( \rho_1(T_1) -
    V_1(T_1,\bar{x}) \right)
\]
where \(q(x)\) and \(L(\bar{x})\) needs to be SOS polynomials.

\subsubsection{Example - embedding a square within a circle}

As a simple example let's have a look at embedding a square within a circle. For
good measure let's give the circle a radius of \(\sqrt{2}+\epsilon\), and the
square a radius of \(1\), and center them both at the origin in the Euclidean
plane.

Starting with defining the set \(\beta\)
\[
  \beta = \set{x \in R^2 \mid \norm{x} \leq 2}
\]
using the manhattan metric. then the implication
\[
  x \in \beta \implies p(x) \geq 0
\]
which can be formulated as
\begin{align*}
  \beta &= \set{x \in \R^2 \mid (1 - x \wedge x + 1) \geq 0} \\
  p(x) &= r^2 - x^2 - y^2
\end{align*}
where \(p(x)\) is the parametrization of the circle, and \(\beta\) is the
parametrization of the square with sides of length two. What needs to be shown
is that \(p(x)\) is positive on the set \(\beta\). Through the
\textit{S-procedure} this can be written as the search for a nonnegative
polynomial \(L_{ineq,i}(x)\) such that \(p(x) \geq \left( sg \right)(x)\). Thus
\[
  q(x) = p(x) - \sum_{i=1}^{2}L_{ineq,i}(x)g_{ineq,i}(x)
\]
is required to be a \ac{SOS} polynomial, along with \(L_{ineq,i}\). From this it
is seen that when a point satisfies \(g_{ineq,i}\) (\ie when \(x \in \beta\))
the term \(\sum_{i=1}^{2}L_{ineq,i}(x)g_{ineq,i}(x)\) is negative, and hence
\(p(x)\) must be nonnegative, which gives the desired implication.

Solving this problem can be done using any of a number of \ac{SOS} modelling
software. This example will rely on \cite[Yalmip]{Lofberg2004} and its \ac{SOS}
programming functionality \cite{Lofberg2009} for \matlab.


\lstinputlisting{figures/funnel/embededsquare.m}

Which returns ``Composition succesful!'' for circles with radii larger than
\(sqrt{2}\) as expected. (Note, this can also be optmized for searching for the
smallest circle which encompasses the square - TODO - do this later.)

\subsection{Region of attraction along a trajectory}

In order to verify regions of attraction along a trajectory, as opposed to
around a single point, some minor modifications to the problem definition has to
be made~\cite{tobenkinInvariantFunnelsTrajectories2010}.

\subsection{Shifting funnels around in the world frame}

* Composition at the ends * Composition in the middle of funnels. ** Cutting off
ends of funnels ** Cutting of heads of funnels * Composing these cut off funnels
at any point in time * Construct a graph which takes these effects into account.


\subsection{Cyclic coordinates and LaGrangian dynamics}

The \funnel\'s generated in this thesis will be motion primitives for the
\rrtfunnel{} algorithm this thesis develops.


