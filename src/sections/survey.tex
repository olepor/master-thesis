\chapter{Survey of Papers}
\label{chp:survey-of-papers}

\section{Focus}
Following is a survey of motion planning techniques that can handle uncertainty.
First described is the relevant sources of uncertainty in motion planning, and
then the relevant techniques that have been applied to solve them in the
literature. In general uncertainty in motion planning can be related to two
sources~\cite{lavalleFrameworkMotionPlanning1995}:
\begin{enumerate}
\item Uncertainty in predictability.
\item Uncertainty in environment.
\end{enumerate}

\section{Uncertainty in Predictability}
Uncertainty in vehicle dynamics arises as the future robot configuration cannot
be predicted exactly. This results from modeling errors and/or limited precision
in the system's command tracking
performance~\cite{dadkhahSurveyMotionPlanning2012}. Thus a transfer from one
state to another will not guarantee full knowledge of the vehicle in the next
state. This is referred to as \textit{automated sequential decision making} in
the literature, and the mathematical framework used to tackle such uncertainty
is the \textit{Markov Decision Process} (MDPs), used to formulate an optimal
value problem, which then can be solved for an optimal value function, and the
corresponding optimal policy~\cite{Cassandra:1998:EAA:926710}. An introduction
to Markov decision processes can be found in \textit{grasping
  POMDPs}~\cite{kaelblingPlanningActingPartially1998}. Here
\citeauthor{kaelblingPlanningActingPartially1998} uses apriori known probability
distributions in order to model uncertainty in the robot model and in the
sensors, then proceeds to use this to solve a number of different objective
functions. By focusing on the parts of space that are most likely to be
encountered, the problem is made tractable for real-life application. The
problem of solving POMDs lies with the size of the state space when this
solution strategy is applied to solving real-world problems -- referred to as
\textit{the curse of dimensionality}. In fact
\citeauthor{christosh.papadimitriouComplexityMarkovDecision1987} showed that
solving such a problem is PSPACE-Complete and thus not tractable for real-life
applications~\cite{christosh.papadimitriouComplexityMarkovDecision1987}. However
approximate solutions are available~\cite{kaelblingPlanningActingPartially1998}.
Therefore the problem has to be solved by using techniques such as sampling the
belief-space~\cite{kearns2002sparse}.
% \subsubsection{Optimal Control Based Approaches}

\section{Uncertainty in Environment}
If the robot has imperfect or non-existent a-priori maps, or noisy sensory data,
complete deterministic knowledge of the environment is impossible. For an
dynamical system in an unknown environment, being able to have the situational
awareness to avoid collisions while adhering to the global planning
requirements, despite unpredicted obstacles appearing, is essential. Thus
environment sensing and mapping and re-planning in real-time is required. This
is referred to in the literature as planning in partially unknown environments.
One solution to this problem is through incremental graph-search algorithms,
such as the \textsl{D*} algorithm, which is described as a method for optimal
and efficient re-planning in partially unknown environments~\cite{Stentz_1997}.
Then \textit{Stentz}, a year later published the \textit{Focused D*} algorithm,
which incorporates heuristics to reduce the total time taken for
re-planning~\cite{Stentz:1995:FDA:1643031.1643113}. Still, \textit{D*} is
computationally heavy, and algorithms have been created to improve on the
time-bound of \textit{D*}. One such implementation is the \textit{D*-lite}
algorithm~\cite{koenig2002d}. These incremental planners, which incorporates the
previously calculated plan in the solution of the newly changed planning problem
speeds up the planning cycles, but can in many cases still not be enough for a
viable real-time solution. Finding a new plan within the allotted planning
interval may simply not be possible, in which case one can resort to
\textit{Anytime} algorithms, like Karaman et.\
al~\cite{karamanAnytimeMotionPlanning2011}, which will find an approximation in
the given time interval. Anytime planners find a solution quickly, and then
spends the rest of the allotted time on improving it until time runs out. One
such example of both an anytime and incremental solution is given in
\textcite{likhachevAnytimeSearchDynamic2008}. Another commonly used technique in
dealing with large state-spaces is sampling, and a popular approach to sampling,
is the \textit{Rapidly Exploring Random Tree} (RRT), which has shown itself
useful in dealing with high dimensional state-spaces. Several RRT-tweaks and
extensions have been proposed over the years, where a good comparison of
different versions of RRT (RRT*, RRT*-smart), can be found
in~\textcite{noreenComparisonRRTRRT2016}. In order to deal with uncertainty, the
\textit{Particle-RRT} (pRRT) is proposed as an extension of the common RRT
algorithm into belief space, and then applied to a rover driving in rough
terrain~\cite{melchiorParticleRRTPath2007}. By propagating the uncertainty along
the planned path, and running this procedure multiple times, a cluster of nodes
is formed. Nodes in the search tree are then formed from these clusters, and a
likelihood can then be assigned to each path. Another RRT-extension is the
\textit{Chance Constrained Rapidly exploring Random Tree} (CC-RRT) algorithm, which can
be employed for efficient identification and execution of probabilistically safe
paths both off-line and on-line in an unknown and uncertain
environment~\cite{Luders_2013}.

\subsubsection{Environment Mapping}

In the case that the map is globally known, the local map may be wrong or have
errors that the on-board local sensors will have to figure out. In the
literature this field is referred to as \textit{Simultaneous Location and
  Mapping} (SLAM). First of all virtually all robotic mapping algorithms are
probabilistic~\cite{thrunRoboticMappingSurvey}. A method which is called
\textit{Occupancy Grid}, in which the map is split up into cells, and each cell
is assigned a given probability of occupancy. It can incorporate information
from high-level maps using the same method that is used for estimating the
occupancy of a cell in a totally unknown environment. As the model is based on
Bayesian estimation, the initial map-data is used as apriori input to the
probabilistic model. Thus the usage of a map of the area is voluntary. In this
way, unknown cells (those that are not yet inspected by local sensors) can be
assigned a high probability of occupancy~\cite{elfes1989using}. An old article
on how this can be implemented on a real robot is given by
Kriegman~\cite{kriegman1987mobile}. More recent work on the Occupancy Grid
explores the trade-off between exploring a new area, and relying on the
information already obtained in order to solve the problem~\cite{7139224}. A
method to integrate current map-data with the on-board filter information relies
on a Bayesian Occupancy Grid Filter for dynamic environments using prior map
knowledge~\cite{gindeleBayesianOccupancyGrid2009}.

\subsubsection{Integrating Planning and Mapping}

Not reasoning about the map and environment uncertainty can lead to crashes, as
further obstacles can be hidden behind known obstacles, and moving into
unexplored territory too fast will almost certainly lead to trouble. Thus using
a combination of sensing, mapping and re-planning is employed in part of the
literature on autonomous motion planning. One method of integrating mapping and
planning is \textit{Chance constrained programming } as shown by
\textcite{vitusHierarchicalMethodStochastic2012}. Here it is shown that
incorporating real-time sensing into the model, which updates the probability a
link in a graph will be traversable depending on how well it has been sensed, is
beneficial to successful operation in an unknown environment. Then a method is
developed for balancing exploration and apriori knowledge of the environment, in
the face of uncertainties in the map. The method is also employed experimentally
on a quad-copter for proof of real-time applicability. Assigning different
probabilities to different paths in the face of uncertainty, is an interesting
way of dealing with e.g.\ time constraints, such as choosing a faster path, with
higher uncertainty when time is short. A method for doing so is given
by~\citeauthor{vandenbergLQGMPOptimizedPath2011} and is based on the
\textit{Linear Quadratic Gaussian Motion Planning} LQG-MP
algorithm~\cite{vandenbergLQGMPOptimizedPath2011}. Another more recent
implementation is done by
\citeauthor{blakeEfficientComputationCollision2018}~\cite{blakeEfficientComputationCollision2018}.
In a motion planner called \textit{Guided Cluster Sampling}, that takes into
account all three sources of uncertainty for robots with active sensing
capabilities are explored by \citeauthor{Kurniawati_2011}. This method builds on
the POMDP framework by utilizing a more suitable sampling distribution based on
the observations done by the robots active sensors~\cite{Kurniawati_2011}. The
\textit{RRT-SLAM} method handles uncertainty a bit differently. This algorithm
handles uncertainty in the RRT-planner by moving the state space up a dimension,
then joining this together with a \textit{Simultaneous Location and Mapping}
(SLAM) procedure~\cite{huangRRTSLAMMotionPlanning2008}.
\citeauthor{bryRapidlyexploringRandomBelief2011} gives an RRT algorithm that
plans in belief space, and incorporates this with an information region where
the robot has little uncertainty, and can thus localize itself. An information
region is a part of the map where the uncertainty in the environment is low, and
the robot can thus relocate itself~\cite{bryRapidlyexploringRandomBelief2011}.
Another approach to dealing with uncertainty and mapping is the \textit{reactive
  planners}. In case of adhering to the \textit{Plan Globally and Act Locally}
paradigm, a reactive planner coupled with a global path planner can provide a
complete navigation solution~\cite{djekouneSensorBasedNavigation2009}. This is
useful in that a perfect map of the environment may not be available. Worse
even, the environment may have changed, as nature is not static. Trees fall
over, and floods move ground, and create hindrances that might not be seen from
a map. Not knowing where a hindrance might lie, or whether one is located
outside the sight of the on-board sensors.

\section{Funnels}

Funnels are first mentioned by \citeauthor{masonMechanicsManipulation1985} in
\citeyear{masonMechanicsManipulation1985}. Then later with the dissertation
\citetitle{parilloStructuredSemidefinitePrograms} by
\citeauthor{parilloStructuredSemidefinitePrograms}, searching for Lyapunov
funnels to verify reachable sets of a nonlinear dynamic system was made possible
through decomposing a \ac{SOS} program into a \ac{SDP} program, solve it with a
numerical solver, and then convert it back again in order to extract the
solution. This was leveraged by \citeauthor{tedrakeLQRtreesFeedbackMotion2009}
to build a tree of \ac{LQR}-controllers, in order to safely take a dynamical
system from one initial state to a final
state~\cite{tedrakeLQRtreesFeedbackMotion2009}. The difference however is that
in this thesis the funnels are computed off-line, and are employed as motion
primitives to a \ac{RRT}-planner, in addition the \ac{LQR}-trees algorithm plans
backwards, while this thesis plans forwards in time. The funnel generation is
also slightly different, as the funnels in this thesis, which is based off of
the formulations by \citeauthor{majumdarFunnelLibrariesRealtime2017}, also seeks
to limit the size of the funnels~\cite{majumdarFunnelLibrariesRealtime2017}. The
ability to handle uncertainty in the funnel \ac{SOS} funnel implementation was
done by \citeauthor{majumdarRobustOnlineMotion2013}, and involved adding a few
extra constraints on the optimization problem employed in order to calculate the
funnels~\cite{majumdarRobustOnlineMotion2013}. Other approaches that are similar
in spirit to this implementation is an \ac{RRT} algorithm which builds a tree of
funnels~\cite{lenySequentialCompositionRobust2012}. The differences however are
that this thesis' algorithm is discrete and the funnels are computed using a
\ac{SOS} framework.

\subsubsection{Motion Primitives}

Applying motion primitives in a \ac{RRT} planner is shown to be beneficial for
generating smoother paths, and offers a significant speedup on the planning
process if the motion primitive library is
sparse~\cite{vonasekGlobalMotionPlanning2013}. An example of motion primitives
offering an advantage to continuously generated motion trajectories is the paper
\citetitle{vonasekHighlevelMotionPlanning2015}, where a modular robot is given
the motion primitives `left', `right', `straight', and the robot is able to get
from the initial to the goal state in reasonable time, despite very complicated
dynamics~\cite{vonasekHighlevelMotionPlanning2015}.
